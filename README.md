# Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves

![GPT-4](https://img.shields.io/badge/Model-GPT--4-green) 
![GPT-3.5](https://img.shields.io/badge/Model-GPT--3.5-green) 
![Vicuna](https://img.shields.io/badge/Model-Vicuna-green) 
![Commonsense Reasoning](https://img.shields.io/badge/Task-Commonsense_Reasoning-red) 
![Symbolic Reasoning](https://img.shields.io/badge/Task-Symbolic_Reasoning-red) 
![Knowledge Classification](https://img.shields.io/badge/Task-Knowledge_Classification-red) 
![Knowledge Comparison](https://img.shields.io/badge/Task-Knowledge_Comparison-red) 
![Stereotypical Bias](https://img.shields.io/badge/Task-Stereotypical_Bias-red) 

This repo holds data and code of the paper "[Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves](https://arxiv.org/abs/2311.04205)".

Authors: Yihe Deng, Weitong Zhang, Zixiang Chen, Quanquan Gu

:speech_balloon: If you have any comments or suggestions, please don't hesitate to comment on the [Twitter](https://uclaml.github.io/PDE/).

[[Webpage](Rephrase-and-Respond)] [[Paper](https://arxiv.org/abs/2311.04205)] [[Huggingface](https://huggingface.co/papers/2311.04205)] [[Twitter]()]

<p align="center">
    <img src="images/demo_RaR.png" width="100%"> <br>
  Demonstration of <b>Rephrase and Respond</b> (RaR). 
</p>

## üîç About RaR
Misunderstandings arise not only in interpersonal communication but also between humans and Large Language Models (LLMs). Such discrepancies can make LLMs interpret seemingly unambiguous questions in unexpected ways, yielding incorrect responses. While it is widely acknowledged that the quality of a prompt, such as a question, significantly impacts the quality of the response provided by LLMs, a systematic method for crafting questions that LLMs can better comprehend is still underdeveloped. 

<p align="center">
    <img src="images/demo_even_month.png" width="80%"> <br>
  An LLM can interpret "even month" as the month with even number of days, which diverges from human intention.
</p>

In this paper, we present a method named ‚ÄòRephrase and Respond‚Äô (RaR), which allows LLMs to rephrase and expand questions posed by humans and provide responses in a single prompt. This approach serves as a simple yet effective prompting method for improving performance. We also introduce a two-step variant of RaR, where a rephrasing LLM first rephrases the question and then passes the original and rephrased questions together to a different responding LLM. This facilitates the effective utilization of rephrased questions generated by one LLM with another. 

```
"{question}"
Rephrase and expand the question, and respond.
```

Our experiments demonstrate that our methods significantly improve the performance of different models across a wide range to tasks. We further provide a comprehensive comparison between RaR and the popular Chain-of-Thought (CoT) methods, both theoretically and empirically. We show that RaR is complementary to CoT and can be combined with CoT to achieve even better performance.

<p align="center">
    <img src="images/exp_results_RaR.png" width="50%"> <br>
  Accuracy (%) comparison of different prompts using GPT-4.
</p>